import os
import re
import sys
import uuid
import time
import json
import asyncio
import aiohttp
from flask import Flask, render_template, request, redirect, url_for, flash, jsonify
import requests
from werkzeug.utils import secure_filename

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MP3_FOLDER'] = 'mp3'
app.config['ALLOWED_EXTENSIONS'] = {'md'}
app.secret_key = 'super-secret-key'  # ç”Ÿäº§ç¯å¢ƒè¯·æ›¿æ¢ä¸ºéšæœºå­—ç¬¦ä¸²

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['MP3_FOLDER'], exist_ok=True)

# å­˜å‚¨æ‰¹é‡å¤„ç†çŠ¶æ€
batch_status = {}

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def safe_filename(filename):
    """å®‰å…¨çš„æ–‡ä»¶åå¤„ç†ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦"""
    import re
    import unicodedata
    
    # å¦‚æœsecure_filenameèƒ½æ­£ç¡®å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨
    secure_name = secure_filename(filename)
    if secure_name and secure_name != filename:
        # å¦‚æœsecure_filenameæ”¹å˜äº†æ–‡ä»¶åï¼Œè¯´æ˜åŸæ–‡ä»¶åæœ‰é—®é¢˜
        # ä½†æˆ‘ä»¬éœ€è¦ä¿ç•™ä¸­æ–‡å­—ç¬¦ï¼Œæ‰€ä»¥ä½¿ç”¨è‡ªå®šä¹‰å¤„ç†
        pass
    else:
        # secure_filenameæ²¡æœ‰æ”¹å˜æ–‡ä»¶åï¼Œè¯´æ˜æ–‡ä»¶åæ˜¯å®‰å…¨çš„
        return filename
    
    # è‡ªå®šä¹‰å¤„ç†ï¼šä¿ç•™ä¸­æ–‡å­—ç¬¦å’ŒåŸºæœ¬ASCIIå­—ç¬¦
    # ç§»é™¤æˆ–æ›¿æ¢å±é™©å­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡
    safe_chars = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '_', filename)
    
    # ç§»é™¤å‰åç©ºæ ¼å’Œç‚¹
    safe_chars = safe_chars.strip('. ')
    
    # é™åˆ¶é•¿åº¦
    if len(safe_chars) > 100:
        safe_chars = safe_chars[:100]
    
    # ç¡®ä¿ä¸ä¸ºç©º
    if not safe_chars:
        safe_chars = "file"
    
    return safe_chars

def generate_batch_directory(custom_name=None):
    """ç”Ÿæˆæ‰¹é‡å¤„ç†ç›®å½•å"""
    if custom_name and custom_name.strip():
        # ä½¿ç”¨è‡ªå®šä¹‰åç§°
        clean_name = clean_directory_name(custom_name.strip())
        return clean_name
    else:
        # ä½¿ç”¨éšæœºåç§°
        timestamp = int(time.time())
        random_id = str(uuid.uuid4())[:8]
        return f"batch_{timestamp}_{random_id}"

def clean_directory_name(name):
    """æ¸…ç†ç›®å½•åç§°ï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    import re
    # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
    clean_name = re.sub(r'[<>:"/\\|?*\x00-\x1f]', '_', name)
    # ç§»é™¤å‰åç©ºæ ¼å’Œç‚¹
    clean_name = clean_name.strip('. ')
    # é™åˆ¶é•¿åº¦
    if len(clean_name) > 50:
        clean_name = clean_name[:50]
    # ç¡®ä¿ä¸ä¸ºç©º
    if not clean_name:
        clean_name = "custom_batch"
    return clean_name

def clean_text(text, options=None):
    """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤ Markdown è¯­æ³•ã€è¡¨æƒ…ç¬¦å·ã€URL é“¾æ¥ç­‰"""
    if not isinstance(text, str):
        text = str(text) if text is not None else ""
    
    cleaned_text = text
    options = options or {}
    
    # ç§»é™¤ Markdown è¯­æ³•
    if options.get('remove_markdown', True):
        # ç§»é™¤å›¾ç‰‡é“¾æ¥
        cleaned_text = re.sub(r'!\[.*?\]\(.*?\)', '', cleaned_text)
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬å†…å®¹
        cleaned_text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', cleaned_text)
        # ç§»é™¤ç²—ä½“æ ‡è®°
        cleaned_text = re.sub(r'\*\*(.*?)\*\*', r'\1', cleaned_text)
        cleaned_text = re.sub(r'__(.*?)__', r'\1', cleaned_text)
        # ç§»é™¤æ–œä½“æ ‡è®°
        cleaned_text = re.sub(r'\*(.*?)\*', r'\1', cleaned_text)
        cleaned_text = re.sub(r'_(.*?)_', r'\1', cleaned_text)
        # ç§»é™¤ä»£ç å—æ ‡è®°
        cleaned_text = re.sub(r'`([^`]+)`', r'\1', cleaned_text)
        # ç§»é™¤æ ‡é¢˜æ ‡è®°
        cleaned_text = re.sub(r'^#{1,6}\s*', '', cleaned_text, flags=re.MULTILINE)
        # ç§»é™¤åˆ—è¡¨æ ‡è®°
        cleaned_text = re.sub(r'^\s*[-*+]\s*', '', cleaned_text, flags=re.MULTILINE)
        # ç§»é™¤æ•°å­—åˆ—è¡¨æ ‡è®°
        cleaned_text = re.sub(r'^\s*\d+\.\s*', '', cleaned_text, flags=re.MULTILINE)
    
    # ç§»é™¤ URL é“¾æ¥
    if options.get('remove_urls', True):
        cleaned_text = re.sub(r'https?://[^\s]+', '', cleaned_text)
    
    # ç§»é™¤è¡¨æƒ…ç¬¦å·
    if options.get('remove_emoji', True):
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„è¡¨æƒ…ç¬¦å·èŒƒå›´ï¼Œé¿å…è¯¯åˆ ä¸­æ–‡å­—ç¬¦
        emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map symbols
            "\U0001F1E0-\U0001F1FF"  # flags (iOS)
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "\U0001F900-\U0001F9FF"  # supplemental symbols
            "\U0001FA70-\U0001FAFF"  # symbols and pictographs extended-a
            "\U00002600-\U000026FF"  # miscellaneous symbols
            "\U00002700-\U000027BF"  # dingbats
            "]+", flags=re.UNICODE)
        cleaned_text = emoji_pattern.sub('', cleaned_text)
    
    # ç§»é™¤å¼•ç”¨æ ‡è®°
    if options.get('remove_citation_numbers', True):
        cleaned_text = re.sub(r'\[\d+\]', '', cleaned_text)
        cleaned_text = re.sub(r'ã€\d+ã€‘', '', cleaned_text)
    
    # åˆå¹¶ä¸ºå•è¡Œæ–‡æœ¬
    if options.get('remove_line_breaks', True):
        # ç§»é™¤æ‰€æœ‰æ¢è¡Œç¬¦
        cleaned_text = re.sub(r'(\r\n|\n|\r)', ' ', cleaned_text)
        # åˆå¹¶å¤šä¸ªè¿ç»­ç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
    else:
        # åªåˆå¹¶éæ¢è¡Œçš„è¿ç»­ç©ºæ ¼
        cleaned_text = re.sub(r'[ \t]+', ' ', cleaned_text)
    
    return cleaned_text.strip()

async def async_text_to_speech(session, text, output_path, voice="zh-CN-XiaoxiaoNeural", speed=1.0, api_url=None, api_key=None):
    """å¼‚æ­¥è°ƒç”¨TTS APIè½¬æ¢æ–‡æœ¬ä¸ºè¯­éŸ³"""
    # ä½¿ç”¨ä¼ å…¥çš„APIä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if not api_url:
        api_url = "http://127.0.0.1:5050/v1/audio/speech"
    else:
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
        if not api_url.endswith('/v1/audio/speech'):
            api_url = api_url.rstrip('/') + '/v1/audio/speech'
    
    if not api_key:
        api_key = "b77cf8cf852f4080bb56a4adcfc6a685"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "tts-1",
        "input": text,  # ç›´æ¥å‘é€åŸå§‹æ–‡æœ¬ï¼Œè®©APIç«¯å¤„ç†æ¸…ç†
        "voice": voice,
        "speed": speed,
        "cleaning_options": {
            "remove_markdown": True,
            "remove_emoji": True,
            "remove_urls": True,
            "remove_line_breaks": True,
            "remove_citation_numbers": True
        }
    }
    
    try:
        # å¼‚æ­¥å‘é€è¯·æ±‚å¹¶è·å–å“åº”
        timeout = aiohttp.ClientTimeout(total=300)  # 5åˆ†é’Ÿè¶…æ—¶
        async with session.post(api_url, headers=headers, json=data, timeout=timeout) as response:
            if response.status == 200:
                # å¼‚æ­¥è¯»å–å“åº”å†…å®¹
                content = await response.read()
                
                # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                with open(output_path, 'wb') as f:
                    f.write(content)
                
                return True
            else:
                print(f"TTS APIè¿”å›é”™è¯¯çŠ¶æ€ç : {response.status} ({api_url})", file=sys.stderr)
                return False
                
    except asyncio.TimeoutError:
        print(f"TTSè½¬æ¢è¶…æ—¶ ({api_url})", file=sys.stderr)
        return False
    except Exception as e:
        print(f"TTSè½¬æ¢å¤±è´¥ ({api_url}): {str(e)}", file=sys.stderr)
        return False

def text_to_speech(text, output_path, voice="zh-CN-XiaoxiaoNeural", speed=1.0, api_url=None, api_key=None):
    """åŒæ­¥ç‰ˆæœ¬çš„TTSè°ƒç”¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    # ä½¿ç”¨ä¼ å…¥çš„APIä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if not api_url:
        api_url = "http://127.0.0.1:5050/v1/audio/speech"
    else:
        # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
        if not api_url.endswith('/v1/audio/speech'):
            api_url = api_url.rstrip('/') + '/v1/audio/speech'
    
    if not api_key:
        api_key = "b77cf8cf852f4080bb56a4adcfc6a685"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "tts-1",
        "input": text,  # ç›´æ¥å‘é€åŸå§‹æ–‡æœ¬ï¼Œè®©APIç«¯å¤„ç†æ¸…ç†
        "voice": voice,
        "speed": speed,
        "cleaning_options": {
            "remove_markdown": True,
            "remove_emoji": True,
            "remove_urls": True,
            "remove_line_breaks": True,
            "remove_citation_numbers": True
        }
    }
    
    try:
        # å‘é€è¯·æ±‚å¹¶è·å–å“åº”
        response = requests.post(api_url, headers=headers, json=data)
        response.raise_for_status()
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(output_path, 'wb') as f:
            f.write(response.content)
        
        return True
    except Exception as e:
        print(f"TTSè½¬æ¢å¤±è´¥ ({api_url}): {str(e)}", file=sys.stderr)
        return False

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_files():
    if 'files' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    files = request.files.getlist('files')
    # è·å–å£°éŸ³å’Œè¯­é€Ÿå‚æ•°
    voice = request.form.get('voice', 'zh-CN-XiaoxiaoNeural')
    speed = float(request.form.get('speed', 1.0))
    custom_directory = request.form.get('custom_directory', '').strip()
    
    # è·å–APIæœåŠ¡å™¨ä¿¡æ¯
    api_servers_json = request.form.get('api_servers', '[]')
    concurrency = int(request.form.get('concurrency', 1))
    
    # è§£æAPIæœåŠ¡å™¨åˆ—è¡¨
    try:
        api_servers = json.loads(api_servers_json)
        # è¿‡æ»¤å‡ºå¯ç”¨çš„æœåŠ¡å™¨
        enabled_servers = [server for server in api_servers if server.get('enabled', True)]
        if not enabled_servers:
            return jsonify({'error': 'æ²¡æœ‰å¯ç”¨çš„APIæœåŠ¡å™¨'}), 400
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºå¯ç”¨çš„æœåŠ¡å™¨
        print(f"ğŸ”§ å¯ç”¨çš„APIæœåŠ¡å™¨åˆ—è¡¨:")
        for i, server in enumerate(enabled_servers):
            print(f"  {i+1}. {server.get('name', 'Unknown')} - {server.get('url', 'No URL')}")
        print(f"ğŸ“Š æ€»å…± {len(enabled_servers)} ä¸ªå¯ç”¨çš„æœåŠ¡å™¨ï¼Œå¹¶å‘åº¦: {concurrency}")
        
    except json.JSONDecodeError:
        return jsonify({'error': 'APIæœåŠ¡å™¨é…ç½®æ ¼å¼é”™è¯¯'}), 400
    
    # ç”Ÿæˆæ‰¹é‡å¤„ç†ç›®å½•
    batch_dir = generate_batch_directory(custom_directory)
    batch_upload_dir = os.path.join(app.config['UPLOAD_FOLDER'], batch_dir)
    
    # åˆ›å»ºæ‰¹é‡å¤„ç†ç›®å½•
    os.makedirs(batch_upload_dir, exist_ok=True)
    
    # åˆå§‹åŒ–æ‰¹é‡çŠ¶æ€
    batch_id = str(uuid.uuid4())
    valid_files = [f for f in files if f and allowed_file(f.filename)]
    batch_status[batch_id] = {
        'total_files': len(valid_files),
        'completed_files': 0,
        'current_file': 0,
        'files': {}
    }
    
    # å…ˆä¿å­˜æ‰€æœ‰æ–‡ä»¶å¹¶åˆå§‹åŒ–çŠ¶æ€
    for file in valid_files:
        filename = safe_filename(file.filename)
        file_id = f"{batch_id}_{filename}"
        
        # ä¿å­˜ä¸Šä¼ çš„Markdownæ–‡ä»¶åˆ°æ‰¹é‡ç›®å½•
        md_path = os.path.join(batch_upload_dir, filename)
        file.save(md_path)
        
        # åˆå§‹åŒ–æ–‡ä»¶çŠ¶æ€
        batch_status[batch_id]['files'][file_id] = {
            'filename': filename,
            'status': 'waiting',
            'progress': 0,
            'stage': 'ç­‰å¾…å¤„ç†'
        }
    
    # å¯åŠ¨åå°å¤„ç†ä»»åŠ¡
    import threading
    thread = threading.Thread(target=run_async_processing, args=(batch_id, batch_upload_dir, voice, speed, enabled_servers, concurrency))
    thread.daemon = True
    thread.start()
    
    return jsonify({
        'batch_id': batch_id,
        'batch_directory': batch_dir,
        'total_files': len(valid_files)
    })

def run_async_processing(batch_id, batch_upload_dir, voice, speed, api_servers, concurrency):
    """è¿è¡Œå¼‚æ­¥å¤„ç†çš„ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # è¿è¡Œå¼‚æ­¥å¤„ç†
        loop.run_until_complete(process_files_async(batch_id, batch_upload_dir, voice, speed, api_servers, concurrency))
        
    except Exception as e:
        print(f"å¼‚æ­¥å¤„ç†å¼‚å¸¸: {str(e)}", file=sys.stderr)
    finally:
        loop.close()

async def process_files_async(batch_id, batch_upload_dir, voice, speed, api_servers, concurrency):
    """å¼‚æ­¥å¤„ç†æ–‡ä»¶ï¼Œä½¿ç”¨çœŸæ­£çš„å¹¶å‘"""
    if batch_id not in batch_status:
        return
    
    batch_info = batch_status[batch_id]
    files_to_process = list(batch_info['files'].keys())
    
    # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºå¼‚æ­¥å¤„ç†é…ç½®
    print(f"ğŸš€ å¼€å§‹å¼‚æ­¥å¤„ç†:")
    print(f"  ğŸ“ æ‰¹æ¬¡ID: {batch_id}")
    print(f"  ğŸ“„ æ–‡ä»¶æ•°é‡: {len(files_to_process)}")
    print(f"  ğŸ–¥ï¸ å¯ç”¨æœåŠ¡å™¨: {len(api_servers)}")
    print(f"  âš¡ å¹¶å‘åº¦: {concurrency}")
    
    # åˆ›å»ºaiohttpä¼šè¯
    connector = aiohttp.TCPConnector(limit=concurrency * 2)  # è¿æ¥æ± é™åˆ¶
    timeout = aiohttp.ClientTimeout(total=300)  # 5åˆ†é’Ÿæ€»è¶…æ—¶
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(concurrency)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = []
        for file_id in files_to_process:
            task = process_single_file_async(session, semaphore, batch_id, batch_upload_dir, voice, speed, api_servers, file_id)
            tasks.append(task)
        
        # ä½¿ç”¨asyncio.gatheråŒæ—¶æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        print(f"ğŸ“¤ åŒæ—¶æäº¤ {len(tasks)} ä¸ªTTSè¯·æ±‚...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        success_count = 0
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                print(f"âŒ ä»»åŠ¡ {i+1} å¼‚å¸¸: {result}")
            elif result:
                success_count += 1
        
        print(f"ğŸ‰ å¼‚æ­¥å¤„ç†å®Œæˆ: {success_count}/{len(files_to_process)} ä¸ªæ–‡ä»¶æˆåŠŸ")
        print(f"ğŸ“Š ä½¿ç”¨äº† {len(api_servers)} ä¸ªæœåŠ¡å™¨ï¼Œå¹¶å‘åº¦: {concurrency}")

async def process_single_file_async(session, semaphore, batch_id, batch_upload_dir, voice, speed, api_servers, file_id):
    """å¼‚æ­¥å¤„ç†å•ä¸ªæ–‡ä»¶"""
    async with semaphore:  # æ§åˆ¶å¹¶å‘æ•°
        try:
            batch_info = batch_status[batch_id]
            file_info = batch_info['files'][file_id]
            filename = file_info['filename']
            
            # æ›´æ–°æ–‡ä»¶çŠ¶æ€
            file_info['status'] = 'processing'
            file_info['progress'] = 10
            file_info['stage'] = 'ğŸ“– è¯»å–æ–‡ä»¶...'
            
            # è¯»å–å®Œæ•´çš„Markdownæ–‡ä»¶å†…å®¹
            md_path = os.path.join(batch_upload_dir, filename)
            
            with open(md_path, 'r', encoding='utf-8') as f:
                full_text = f.read()
            
            file_info['progress'] = 20
            file_info['stage'] = 'ğŸ“¤ å‡†å¤‡å‘é€åˆ°TTS API...'
            
            # ç”ŸæˆMP3æ–‡ä»¶è·¯å¾„
            mp3_filename = os.path.splitext(filename)[0] + '.mp3'
            mp3_path = os.path.join(batch_upload_dir, mp3_filename)
            
            file_info['progress'] = 30
            file_info['stage'] = 'â³ ç­‰å¾…TTSå¤„ç†ä¸­...'
            
            # è´Ÿè½½å‡è¡¡ï¼šè½®è¯¢é€‰æ‹©æœåŠ¡å™¨
            server_index = hash(file_id) % len(api_servers)  # ä½¿ç”¨å“ˆå¸Œç¡®ä¿ä¸€è‡´æ€§
            selected_server = api_servers[server_index]
            
            server_name = selected_server.get('name', 'Unknown')
            api_url = selected_server.get('url', '')
            api_key = selected_server.get('apiKey', '')
            
            # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºæœåŠ¡å™¨åˆ†é…
            print(f"ğŸ”„ æ–‡ä»¶ {filename} åˆ†é…ç»™æœåŠ¡å™¨: {server_name} ({api_url})")
            
            file_info['stage'] = f'â³ ä½¿ç”¨æœåŠ¡å™¨ {server_name} å¤„ç†ä¸­...'
            
            # å¼‚æ­¥è°ƒç”¨TTSè½¬æ¢
            success = await async_text_to_speech(session, full_text, mp3_path, voice, speed, api_url, api_key)
            
            if success:
                file_info['progress'] = 90
                file_info['stage'] = 'ğŸ’¾ ä¿å­˜éŸ³é¢‘æ–‡ä»¶...'
                
                file_info['status'] = 'completed'
                file_info['progress'] = 100
                file_info['stage'] = 'âœ… è½¬æ¢å®Œæˆ'
                print(f"âœ… {filename} è½¬æ¢æˆåŠŸ (æœåŠ¡å™¨: {server_name})")
            else:
                file_info['status'] = 'failed'
                file_info['progress'] = 100
                file_info['stage'] = f'âŒ è½¬æ¢å¤±è´¥ (æœåŠ¡å™¨: {server_name})'
                print(f"âŒ {filename} è½¬æ¢å¤±è´¥ (æœåŠ¡å™¨: {server_name})")
            
            # æ›´æ–°å®Œæˆè®¡æ•°
            batch_info['completed_files'] += 1
            batch_info['current_file'] = batch_info['completed_files']
            
            return success
            
        except Exception as e:
            file_info['status'] = 'failed'
            file_info['progress'] = 100
            file_info['stage'] = f'âŒ å¤„ç†å¼‚å¸¸: {str(e)}'
            print(f"âŒ {filename} å¤„ç†å¼‚å¸¸: {str(e)}")
            batch_info['completed_files'] += 1
            batch_info['current_file'] = batch_info['completed_files']
            return False

def process_files_with_load_balancing(batch_id, batch_upload_dir, voice, speed, api_servers, concurrency):
    """ä½¿ç”¨è´Ÿè½½å‡è¡¡å’Œå¹¶å‘å¤„ç†æ–‡ä»¶"""
    if batch_id not in batch_status:
        return
    
    batch_info = batch_status[batch_id]
    files_to_process = list(batch_info['files'].keys())
    
    # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºè´Ÿè½½å‡è¡¡é…ç½®
    print(f"ğŸš€ å¼€å§‹è´Ÿè½½å‡è¡¡å¤„ç†:")
    print(f"  ğŸ“ æ‰¹æ¬¡ID: {batch_id}")
    print(f"  ğŸ“„ æ–‡ä»¶æ•°é‡: {len(files_to_process)}")
    print(f"  ğŸ–¥ï¸ å¯ç”¨æœåŠ¡å™¨: {len(api_servers)}")
    print(f"  âš¡ å¹¶å‘åº¦: {concurrency}")
    
    # åˆ›å»ºæœåŠ¡å™¨è½®è¯¢ç´¢å¼•
    server_index = 0
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘å¤„ç†
    import threading
    from concurrent.futures import ThreadPoolExecutor, as_completed
    import queue
    
    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
    task_queue = queue.Queue()
    for file_id in files_to_process:
        task_queue.put(file_id)
    
    # åˆ›å»ºçº¿ç¨‹æ± 
    max_workers = min(concurrency, len(files_to_process), len(api_servers))
    
    def process_single_file(file_id):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            file_info = batch_info['files'][file_id]
            filename = file_info['filename']
            
            # æ›´æ–°æ–‡ä»¶çŠ¶æ€
            file_info['status'] = 'processing'
            file_info['progress'] = 10
            file_info['stage'] = 'ğŸ“– è¯»å–æ–‡ä»¶...'
            
            # è¯»å–å®Œæ•´çš„Markdownæ–‡ä»¶å†…å®¹
            md_path = os.path.join(batch_upload_dir, filename)
            
            with open(md_path, 'r', encoding='utf-8') as f:
                full_text = f.read()
            
            file_info['progress'] = 20
            file_info['stage'] = 'ğŸ“¤ å‡†å¤‡å‘é€åˆ°TTS API...'
            
            # ç”ŸæˆMP3æ–‡ä»¶è·¯å¾„
            mp3_filename = os.path.splitext(filename)[0] + '.mp3'
            mp3_path = os.path.join(batch_upload_dir, mp3_filename)
            
            file_info['progress'] = 30
            file_info['stage'] = 'â³ ç­‰å¾…TTSå¤„ç†ä¸­...'
            
            # è´Ÿè½½å‡è¡¡ï¼šè½®è¯¢é€‰æ‹©æœåŠ¡å™¨
            nonlocal server_index
            selected_server = api_servers[server_index % len(api_servers)]
            server_index += 1
            
            server_name = selected_server.get('name', 'Unknown')
            api_url = selected_server.get('url', '')
            api_key = selected_server.get('apiKey', '')
            
            # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºæœåŠ¡å™¨åˆ†é…
            print(f"ğŸ”„ æ–‡ä»¶ {filename} åˆ†é…ç»™æœåŠ¡å™¨: {server_name} ({api_url})")
            
            file_info['stage'] = f'â³ ä½¿ç”¨æœåŠ¡å™¨ {server_name} å¤„ç†ä¸­...'
            
            # è°ƒç”¨TTSè½¬æ¢
            success = text_to_speech(full_text, mp3_path, voice, speed, api_url, api_key)
            
            if success:
                file_info['progress'] = 90
                file_info['stage'] = 'ğŸ’¾ ä¿å­˜éŸ³é¢‘æ–‡ä»¶...'
                
                file_info['status'] = 'completed'
                file_info['progress'] = 100
                file_info['stage'] = 'âœ… è½¬æ¢å®Œæˆ'
                print(f"âœ… {filename} è½¬æ¢æˆåŠŸ (æœåŠ¡å™¨: {server_name})")
            else:
                file_info['status'] = 'failed'
                file_info['progress'] = 100
                file_info['stage'] = f'âŒ è½¬æ¢å¤±è´¥ (æœåŠ¡å™¨: {server_name})'
                print(f"âŒ {filename} è½¬æ¢å¤±è´¥ (æœåŠ¡å™¨: {server_name})")
            
            return file_id, success
            
        except Exception as e:
            file_info['status'] = 'failed'
            file_info['progress'] = 100
            file_info['stage'] = f'âŒ å¤„ç†å¼‚å¸¸: {str(e)}'
            print(f"âŒ {filename} å¤„ç†å¼‚å¸¸: {str(e)}")
            return file_id, False
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œä»»åŠ¡
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_file = {
            executor.submit(process_single_file, file_id): file_id 
            for file_id in files_to_process
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_file):
            file_id, success = future.result()
            batch_info['completed_files'] += 1
            
            # æ›´æ–°å½“å‰å¤„ç†æ–‡ä»¶è®¡æ•°
            batch_info['current_file'] = batch_info['completed_files']
    
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ: {batch_info['completed_files']}/{batch_info['total_files']} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“Š ä½¿ç”¨äº† {len(api_servers)} ä¸ªæœåŠ¡å™¨ï¼Œå¹¶å‘åº¦: {max_workers}")

@app.route('/progress/<batch_id>')
def get_progress(batch_id):
    """è·å–æ‰¹é‡å¤„ç†è¿›åº¦"""
    if batch_id not in batch_status:
        return jsonify({'error': 'æ‰¹æ¬¡ä¸å­˜åœ¨'}), 404
    
    status = batch_status[batch_id]
    return jsonify({
        'batch_id': batch_id,
        'total_files': status['total_files'],
        'completed_files': status['completed_files'],
        'current_file': status.get('current_file', 0),
        'files': status['files']
    })

if __name__ == '__main__':
    app.run(debug=True)